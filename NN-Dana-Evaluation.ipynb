{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dlansigan/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense,Activation,Dropout \n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(csv_file='ncsr_clean.csv', balance=True, random_seed=0):\n",
    "    # Read csv\n",
    "    df=pd.read_csv(csv_file).drop(['Unnamed: 0'], axis=1)\n",
    "    df=df.loc[:293]\n",
    "    \n",
    "    if balance:\n",
    "        df=df.append(df[df['Y']==0])\n",
    "        \n",
    "    # Get x and y values\n",
    "    np.random.seed(random_seed)\n",
    "    shuffled_idx=shuffle(range(len(df)))\n",
    "    shuffled_df=df.iloc[shuffled_idx]\n",
    "    y=shuffled_df['Y'].values\n",
    "    X=shuffled_df.drop(['Y'], axis=1)\n",
    "    X=(X-X.mean())/X.std()\n",
    "    X=X/X.max()\n",
    "    X=X.values\n",
    "    \n",
    "    return X,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTest(X,y, test_size=0.1):\n",
    "    # Split\n",
    "    test_size=int(np.round(test_size*len(y)))\n",
    "    X_test=X[:test_size]\n",
    "    X=X[test_size:]\n",
    "    y_test=y[:test_size]\n",
    "    y=y[test_size:]    \n",
    "    return X, X_test, y, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model=keras.models.load_model('NN_Dana.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=loadData()\n",
    "X,X_test,y,y_test=splitTest(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  5]\n",
      " [ 6 12]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6857142857142857"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction=model.predict(X_test).argmax(axis=1)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, prediction))\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
